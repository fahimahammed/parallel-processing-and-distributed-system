1. Write a simple C++ program in MPI to multiply two matrices of size MxN and NxP .

#include <iostream>
#include <mpi.h>

using namespace std;

const int M = 3;
const int N = 3;
const int P = 3;

void matrix_multiply(int A[M][N], int B[N][P], int C[M][P], int row_start, int row_end) {
    for (int i = row_start; i < row_end; i++) {
        for (int j = 0; j < P; j++) {
            C[i][j] = 0;
            for (int k = 0; k < N; k++) {
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}

int main(int argc, char** argv) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int A[M][N] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};
    int B[N][P] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};
    int C[M][P];

    int rows_per_process = M / size;
    int row_start = rank * rows_per_process;
    int row_end = (rank == size - 1) ? M : row_start + rows_per_process;

    matrix_multiply(A, B, C, row_start, row_end);

    int recv_buffer[M][P];
    MPI_Allgather(C, rows_per_process * P, MPI_INT, recv_buffer, rows_per_process * P, MPI_INT, MPI_COMM_WORLD);

    if (rank == 0) {
        cout << "Matrix A:" << endl;
        for (int i = 0; i < M; i++) {
            for (int j = 0; j < N; j++) {
                cout << A[i][j] << " ";
            }
            cout << endl;
        }

        cout << "Matrix B:" << endl;
        for (int i = 0; i < N; i++) {
            for (int j = 0; j < P; j++) {
                cout << B[i][j] << " ";
            }
            cout << endl;
        }

        cout << "Result Matrix C:" << endl;
        for (int i = 0; i < M; i++) {
            for (int j = 0; j < P; j++) {
                cout << recv_buffer[i][j] << " ";
            }
            cout << endl;
        }
    }

    MPI_Finalize();
    return 0;
}

2. Write a program in MPI to simulate a simple calculator. Perform each operation using a different process in parallel .
#include <iostream>
#include <mpi.h>

using namespace std;

int main(int argc, char** argv) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int operand1 = 10;
    int operand2 = 5;
    int result = 0;

    if (rank == 0) {
        // Addition
        result = operand1 + operand2;
        cout << "Process 0: Addition (" << operand1 << " + " << operand2 << ") = " << result << endl;
    } else if (rank == 1) {
        // Subtraction
        result = operand1 - operand2;
        cout << "Process 1: Subtraction (" << operand1 << " - " << operand2 << ") = " << result << endl;
    } else if (rank == 2) {
        // Multiplication
        result = operand1 * operand2;
        cout << "Process 2: Multiplication (" << operand1 << " * " << operand2 << ") = " << result << endl;
    } else if (rank == 3) {
        // Division (with error checking)
        if (operand2 != 0) {
            result = operand1 / operand2;
            cout << "Process 3: Division (" << operand1 << " / " << operand2 << ") = " << result << endl;
        } else {
            cerr << "Process 3: Division by zero is not allowed." << endl;
        }
    }

    MPI_Finalize();
    return 0;
}


3. Write a program in C++ to count the words in a file and sort it in descending order of frequency of words that is, the highest occurring word must come first and least occurring word must come last.
#include <iostream>
#include <fstream>
#include <sstream>
#include <map>
#include <vector>
#include <algorithm>

using namespace std;

// Function to tokenize a string into words
vector<string> tokenize(const string& str) {
    vector<string> tokens;
    stringstream ss(str);
    string token;
    while (ss >> token) {
        tokens.push_back(token);
    }
    return tokens;
}

int main() {
    string filename = "sample.txt"; // Change this to your input file name

    ifstream inputFile(filename);
    if (!inputFile) {
        cerr << "Error: Unable to open file " << filename << endl;
        return 1;
    }

    map<string, int> wordCount;

    string line;
    while (getline(inputFile, line)) {
        vector<string> words = tokenize(line);
        for (const string& word : words) {
            // Convert the word to lowercase (if needed) for case-insensitive counting
            // You can remove this line if you want case-sensitive counting
            transform(word.begin(), word.end(), word.begin(), ::tolower);

            // Increment the word count
            wordCount[word]++;
        }
    }

    // Create a vector of pairs for sorting
    vector<pair<string, int>> wordFrequencyPairs;
    for (const auto& entry : wordCount) {
        wordFrequencyPairs.push_back(entry);
    }

    // Sort the vector in descending order of word frequency
    sort(wordFrequencyPairs.begin(), wordFrequencyPairs.end(),
         [](const pair<string, int>& a, const pair<string, int>& b) {
             return a.second > b.second;
         });

    // Print the sorted word frequency list
    for (const auto& pair : wordFrequencyPairs) {
        cout << pair.first << ": " << pair.second << " times" << endl;
    }

    inputFile.close();
    return 0;
}

4. Write a MPI program using synchronous send. The sender process sends a word to the receiver. The second process receives the word, toggles each letter of the word and sends it back to the first process. Both processes use synchronous send operations.
#include <iostream>
#include <string>
#include <mpi.h>

using namespace std;

int main(int argc, char** argv) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    if (size != 2) {
        cerr << "This program requires exactly 2 processes." << endl;
        MPI_Finalize();
        return 1;
    }

    if (rank == 0) {
        string word = "hello";
        MPI_Send(word.c_str(), word.size(), MPI_CHAR, 1, 0, MPI_COMM_WORLD);

        cout << "Process 0 sent: " << word << endl;

        char received_word[word.size()];
        MPI_Recv(received_word, word.size(), MPI_CHAR, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

        cout << "Process 0 received: " << received_word << endl;
    } else if (rank == 1) {
        char received_word[5];
        MPI_Recv(received_word, 5, MPI_CHAR, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

        cout << "Process 1 received: " << received_word << endl;

        // Toggle each letter in the word
        for (int i = 0; i < 5; i++) {
            if (islower(received_word[i])) {
                received_word[i] = toupper(received_word[i]);
            } else if (isupper(received_word[i])) {
                received_word[i] = tolower(received_word[i]);
            }
        }

        MPI_Ssend(received_word, 5, MPI_CHAR, 0, 0, MPI_COMM_WORLD);

        cout << "Process 1 sent back: " << received_word << endl;
    }

    MPI_Finalize();
    return 0;
}

5. Write a MPI program to add an array of size N using two processes. Print theresult in the root process. Investigate the amount of time taken by each process.
#include <iostream>
#include <mpi.h>
#include <vector>
#include <ctime>

using namespace std;

int main(int argc, char** argv) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int N = 1000000; // Size of the array
    vector<int> array(N);

    if (size != 2) {
        cerr << "This program requires exactly 2 processes." << endl;
        MPI_Finalize();
        return 1;
    }

    if (rank == 0) {
        // Initialize the array with values 1 to N
        for (int i = 0; i < N; i++) {
            array[i] = i + 1;
        }

        // Measure the start time
        double start_time = MPI_Wtime();

        // Send half of the array to process 1
        MPI_Send(array.data() + N / 2, N / 2, MPI_INT, 1, 0, MPI_COMM_WORLD);

        // Calculate the sum of the first half of the array
        long long local_sum = 0;
        for (int i = 0; i < N / 2; i++) {
            local_sum += array[i];
        }

        // Receive the sum from process 1
        long long remote_sum;
        MPI_Recv(&remote_sum, 1, MPI_LONG_LONG, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

        // Calculate the final sum
        long long final_sum = local_sum + remote_sum;

        // Measure the end time
        double end_time = MPI_Wtime();

        cout << "Process 0: Sum of array elements = " << final_sum << endl;
        cout << "Process 0: Time taken = " << end_time - start_time << " seconds" << endl;
    } else if (rank == 1) {
        // Receive the second half of the array from process 0
        MPI_Recv(array.data() + N / 2, N / 2, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

        // Calculate the sum of the second half of the array
        long long local_sum = 0;
        for (int i = N / 2; i < N; i++) {
            local_sum += array[i];
        }

        // Send the sum back to process 0
        MPI_Send(&local_sum, 1, MPI_LONG_LONG, 0, 0, MPI_COMM_WORLD);
    }

    MPI_Finalize();
    return 0;
}

6.   Write a Cuda program for matrix multiplication.
#include <iostream>
#include <cstdlib>
#include <ctime>
#include <cuda_runtime.h>

using namespace std;

// Matrix dimensions
const int M = 4; // Number of rows in matrix A
const int N = 4; // Number of columns in matrix A and rows in matrix B
const int P = 4; // Number of columns in matrix B

// Function to initialize a matrix with random values
void initializeMatrix(int* matrix, int rows, int cols) {
    for (int i = 0; i < rows; i++) {
        for (int j = 0; j < cols; j++) {
            matrix[i * cols + j] = rand() % 10; // Generate random values between 0 and 9
        }
    }
}

// Kernel function for matrix multiplication
__global__ void matrixMultiply(int* A, int* B, int* C, int M, int N, int P) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int sum = 0;

    if (row < M && col < P) {
        for (int i = 0; i < N; i++) {
            sum += A[row * N + i] * B[i * P + col];
        }
        C[row * P + col] = sum;
    }
}

int main() {
    // Initialize random seed
    srand(time(nullptr));

    // Allocate memory for matrices on the host
    int* A = new int[M * N];
    int* B = new int[N * P];
    int* C = new int[M * P];

    // Initialize matrices A and B with random values
    initializeMatrix(A, M, N);
    initializeMatrix(B, N, P);

    // Allocate memory for matrices on the device (GPU)
    int* d_A, *d_B, *d_C;
    cudaMalloc((void**)&d_A, sizeof(int) * M * N);
    cudaMalloc((void**)&d_B, sizeof(int) * N * P);
    cudaMalloc((void**)&d_C, sizeof(int) * M * P);

    // Copy matrices A and B from host to device
    cudaMemcpy(d_A, A, sizeof(int) * M * N, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, sizeof(int) * N * P, cudaMemcpyHostToDevice);

    // Define grid and block dimensions for CUDA kernel
    dim3 blockDim(16, 16); // 16x16 thread block
    dim3 gridDim((P + blockDim.x - 1) / blockDim.x, (M + blockDim.y - 1) / blockDim.y);

    // Launch CUDA kernel for matrix multiplication
    matrixMultiply<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, N, P);

    // Copy the result matrix C from device to host
    cudaMemcpy(C, d_C, sizeof(int) * M * P, cudaMemcpyDeviceToHost);

    // Print the result matrix C
    cout << "Result Matrix C:" << endl;
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < P; j++) {
            cout << C[i * P + j] << "\t";
        }
        cout << endl;
    }

    // Free allocated memory on the device and host
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
    delete[] A;
    delete[] B;
    delete[] C;

    return 0;
}
7.Write a Cuda program to find out maximum common subsequence.
#include <iostream>
#include <vector>
#include <algorithm>
#include <cuda_runtime.h>

using namespace std;

__global__ void findLCS(int* seq1, int* seq2, int* result, int n, int m) {
    // Implement dynamic programming for LCS here (e.g., using shared memory)
    // Each thread can compute a part of the LCS table
}

int main() {
    // Define input sequences
    vector<int> sequence1 = {1, 2, 3, 4, 5};
    vector<int> sequence2 = {3, 4, 5, 6, 7};

    // Get the lengths of the sequences
    int n = sequence1.size();
    int m = sequence2.size();

    // Allocate memory on the GPU for sequences and LCS result
    int* d_seq1, *d_seq2, *d_result;
    cudaMalloc((void**)&d_seq1, sizeof(int) * n);
    cudaMalloc((void**)&d_seq2, sizeof(int) * m);
    cudaMalloc((void**)&d_result, sizeof(int) * (n + 1) * (m + 1));

    // Copy input sequences to the GPU
    cudaMemcpy(d_seq1, sequence1.data(), sizeof(int) * n, cudaMemcpyHostToDevice);
    cudaMemcpy(d_seq2, sequence2.data(), sizeof(int) * m, cudaMemcpyHostToDevice);

    // Launch the CUDA kernel to find LCS
    dim3 grid(1, 1);
    dim3 block(1, 1);
    findLCS<<<grid, block>>>(d_seq1, d_seq2, d_result, n, m);

    // Copy the result back from the GPU
    int result;
    cudaMemcpy(&result, d_result, sizeof(int), cudaMemcpyDeviceToHost);

    // Free allocated GPU memory
    cudaFree(d_seq1);
    cudaFree(d_seq2);
    cudaFree(d_result);

    cout << "Maximum Common Subsequence (LCS) length: " << result << endl;

    return 0;
}

8. Given a paragraph and a pattern like %x%. Now write a cuda program to find out the line number where %x% this pattern exists in the given paragraph.
#include <iostream>
#include <vector>
#include <string>
#include <cuda_runtime.h>

using namespace std;

__global__ void findPattern(char* paragraph, char* pattern, int* result, int paragraphLength, int patternLength) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int patternIndex = 0;
    int paragraphIndex = tid;

    while (paragraphIndex < paragraphLength) {
        if (paragraph[paragraphIndex] == pattern[patternIndex]) {
            paragraphIndex++;
            patternIndex++;

            if (patternIndex == patternLength) {
                result[blockIdx.x] = paragraphIndex - patternLength;
                return; // Pattern found, exit
            }
        } else if (patternIndex > 0) {
            patternIndex = 0; // Reset pattern index
        } else {
            paragraphIndex++;
        }
    }

    result[blockIdx.x] = -1; // Pattern not found
}

int main() {
    string paragraph = "This is a sample paragraph with a pattern %x% in it. %x% can appear multiple times.";
    string pattern = "%x%";

    int paragraphLength = paragraph.length();
    int patternLength = pattern.length();

    // Allocate memory on the GPU for paragraph, pattern, and result
    char* d_paragraph, *d_pattern;
    int* d_result;

    cudaMalloc((void**)&d_paragraph, paragraphLength * sizeof(char));
    cudaMalloc((void**)&d_pattern, patternLength * sizeof(char));
    cudaMalloc((void**)&d_result, sizeof(int));

    // Copy paragraph and pattern to the GPU
    cudaMemcpy(d_paragraph, paragraph.c_str(), paragraphLength * sizeof(char), cudaMemcpyHostToDevice);
    cudaMemcpy(d_pattern, pattern.c_str(), patternLength * sizeof(char), cudaMemcpyHostToDevice);

    // Define grid and block dimensions for CUDA kernel
    dim3 grid(1, 1);
    dim3 block(paragraphLength, 1);

    // Launch the CUDA kernel to find the pattern in the paragraph
    findPattern<<<grid, block>>>(d_paragraph, d_pattern, d_result, paragraphLength, patternLength);

    // Copy the result back from the GPU
    int result;
    cudaMemcpy(&result, d_result, sizeof(int), cudaMemcpyDeviceToHost);

    // Free allocated GPU memory
    cudaFree(d_paragraph);
    cudaFree(d_pattern);
    cudaFree(d_result);

    if (result != -1) {
        cout << "Pattern found in line: " << result << endl;
    } else {
        cout << "Pattern not found in the paragraph." << endl;
    }

    return 0;
}


